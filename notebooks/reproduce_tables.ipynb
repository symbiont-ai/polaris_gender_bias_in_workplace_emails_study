{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing Tables from the Paper\n",
    "\n",
    "This notebook reproduces all tables from \"Disentangling Generation and LLM-Judge Effects in Workplace Emails: Gender-Coded Differences Across Models\"\n",
    "\n",
    "**Statistical approach:** Paired Wilcoxon signed-rank tests with 95% CIs and BH-FDR correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from analyze_results import (load_emails, load_ratings, \n",
    "                             paired_pattern_analysis, paired_rating_analysis,\n",
    "                             apply_bh_correction)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_dir = Path('../data/raw')\n",
    "\n",
    "gpt_emails = load_emails(data_dir / 'emails_gpt52.json')\n",
    "gemini_emails = load_emails(data_dir / 'emails_gemini.json')\n",
    "\n",
    "ratings = {\n",
    "    'gemini_nat': load_ratings(data_dir / 'ratings_gemini_naturalistic.json'),\n",
    "    'gemini_deb': load_ratings(data_dir / 'ratings_gemini_debiased.json'),\n",
    "    'gemini_blind': load_ratings(data_dir / 'ratings_gemini_blinded.json'),\n",
    "    'gpt52_nat': load_ratings(data_dir / 'ratings_gpt52_naturalistic.json'),\n",
    "    'gpt52_deb': load_ratings(data_dir / 'ratings_gpt52_debiased.json'),\n",
    "    'gpt52_blind': load_ratings(data_dir / 'ratings_gpt52_blinded.json'),\n",
    "}\n",
    "\n",
    "print(f\"Emails: {len(gpt_emails)} GPT-5.2, {len(gemini_emails)} Gemini\")\n",
    "print(f\"Ratings: {sum(len(v) for v in ratings.values())} total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2: Generation Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    ('i_believe', r'\\bi believe\\b', re.IGNORECASE),\n",
    "    ('given_my', r'given my', re.IGNORECASE),\n",
    "    ('wanted_to', r'wanted to', re.IGNORECASE),\n",
    "    ('follow_up', r'follow.?up', re.IGNORECASE),\n",
    "    ('clarify', r'\\bclarify\\b', re.IGNORECASE),\n",
    "    ('full_name_sig', r'\\n[A-Z][a-z]+ [A-Z][a-z]+\\s*$', 0),\n",
    "]\n",
    "\n",
    "all_patterns = []\n",
    "for scenario in ['S01', 'S02']:\n",
    "    for model_name, emails in [('GPT-5.2', gpt_emails), ('Gemini 2.0', gemini_emails)]:\n",
    "        for pattern_name, pattern, flags in patterns:\n",
    "            res = paired_pattern_analysis(emails, scenario, pattern, flags)\n",
    "            all_patterns.append({\n",
    "                'Scenario': scenario, 'Model': model_name, 'Pattern': pattern_name, **res\n",
    "            })\n",
    "\n",
    "all_patterns = apply_bh_correction(all_patterns)\n",
    "\n",
    "# Show significant patterns\n",
    "sig_df = pd.DataFrame([p for p in all_patterns if p['significant']])\n",
    "sig_df[['Scenario', 'Model', 'Pattern', 'f_pct', 'm_pct', 'diff', 'ci_low', 'ci_high', 'p', 'd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 3: S01 Evaluation (Salary Negotiation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s01_results = []\n",
    "for setting, condition, key in [\n",
    "    ('GPT-5.2 → Gemini 2.0', 'Naturalistic', 'gemini_nat'),\n",
    "    ('GPT-5.2 → Gemini 2.0', 'Debiased', 'gemini_deb'),\n",
    "    ('GPT-5.2 → Gemini 2.0', 'Blinded', 'gemini_blind'),\n",
    "    ('Gemini 2.0 → GPT-5.2', 'Naturalistic', 'gpt52_nat'),\n",
    "    ('Gemini 2.0 → GPT-5.2', 'Debiased', 'gpt52_deb'),\n",
    "    ('Gemini 2.0 → GPT-5.2', 'Blinded', 'gpt52_blind'),\n",
    "]:\n",
    "    res = paired_rating_analysis(ratings[key], 'S01', 'likelihood_to_grant_raise')\n",
    "    if res:\n",
    "        s01_results.append({'Setting': setting, 'Condition': condition, **res})\n",
    "\n",
    "pd.DataFrame(s01_results)[['Setting', 'Condition', 'diff', 'ci_low', 'ci_high', 'p']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 4: S02 Evaluation (Credit Attribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s02_results = []\n",
    "for setting, condition, key in [\n",
    "    ('GPT-5.2 → Gemini 2.0', 'Naturalistic', 'gemini_nat'),\n",
    "    ('GPT-5.2 → Gemini 2.0', 'Debiased', 'gemini_deb'),\n",
    "    ('GPT-5.2 → Gemini 2.0', 'Blinded', 'gemini_blind'),\n",
    "    ('Gemini 2.0 → GPT-5.2', 'Naturalistic', 'gpt52_nat'),\n",
    "    ('Gemini 2.0 → GPT-5.2', 'Debiased', 'gpt52_deb'),\n",
    "    ('Gemini 2.0 → GPT-5.2', 'Blinded', 'gpt52_blind'),\n",
    "]:\n",
    "    res = paired_rating_analysis(ratings[key], 'S02', 'likelihood_to_send_correction')\n",
    "    if res:\n",
    "        s02_results.append({'Setting': setting, 'Condition': condition, 'key': key, **res})\n",
    "\n",
    "pd.DataFrame(s02_results)[['Setting', 'Condition', 'diff', 'ci_low', 'ci_high', 'p', 'd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 5: Bias Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s02_by_key = {r['key']: r for r in s02_results}\n",
    "\n",
    "decomp = []\n",
    "for evaluator, nat_key, blind_key, deb_key in [\n",
    "    ('Gemini 2.0', 'gemini_nat', 'gemini_blind', 'gemini_deb'),\n",
    "    ('GPT-5.2', 'gpt52_nat', 'gpt52_blind', 'gpt52_deb'),\n",
    "]:\n",
    "    nat = s02_by_key[nat_key]\n",
    "    blind = s02_by_key[blind_key]\n",
    "    deb = s02_by_key[deb_key]\n",
    "    \n",
    "    decomp.append({\n",
    "        'Evaluator': evaluator,\n",
    "        'Unblinded': f\"+{nat['diff']:.2f} (d={nat['d']:.2f})\",\n",
    "        'Blinded': f\"+{blind['diff']:.2f} (d={blind['d']:.2f})\",\n",
    "        'Debiased': f\"+{deb['diff']:.2f}\",\n",
    "        'Name Component': f\"{nat['diff'] - blind['diff']:+.2f}\",\n",
    "        'Style Component': f\"+{blind['diff']:.2f}\",\n",
    "        'Interpretation': 'Pure style' if abs(nat['diff'] - blind['diff']) < 0.05 else 'Name + style'\n",
    "    })\n",
    "\n",
    "pd.DataFrame(decomp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
